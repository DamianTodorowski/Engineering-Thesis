{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-11T18:18:30.669796Z",
     "start_time": "2025-11-11T18:18:24.873810Z"
    }
   },
   "source": [
    "#Importy i Przygotowanie Danych\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from keras import layers, models\n",
    "\n",
    "# Ustawienie seed dla powtarzalności\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"Wersja TensorFlow: {tf.__version__}\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wersja TensorFlow: 2.20.0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T18:18:34.199577Z",
     "start_time": "2025-11-11T18:18:34.143752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Ładowanie danych (Iris)\n",
    "data = load_iris()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "\n",
    "X = df.drop(columns=['target']).values\n",
    "y = df['target'].values\n",
    "\n",
    "# Standaryzacja\n",
    "# Skalowanie jest kluczowe, aby cechy miały średnią 0 i odchylenie standardowe 1.\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Zakres danych po skalowaniu jest potrzebny do poprawnego \"klippowania\"\n",
    "# (przycinania) perturbacji adwersarialnych, aby zachować sensowne wartości.\n",
    "min_val, max_val = X_scaled.min(), X_scaled.max()\n",
    "print(f\"Zakres danych po skalowaniu: [{min_val:.3f}, {max_val:.3f}]\")\n",
    "\n",
    "# --- Podział na zbiory treningowy i testowy ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Kształt zbioru treningowego: {X_train.shape}\")"
   ],
   "id": "885e1ec1090ad2f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zakres danych po skalowaniu: [-2.434, 3.091]\n",
      "Kształt zbioru treningowego: (120, 4)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T18:19:20.112896Z",
     "start_time": "2025-11-11T18:19:17.734563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Prosta sieć MLP (Multilayer Perceptron)\n",
    "def create_model(input_dim):\n",
    "    \"\"\"Tworzy model MLP z dwiema warstwami ukrytymi.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        # Warstwa wyjściowa: 3 klasy, aktywacja softmax\n",
    "        layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy', # Używamy dla etykiet skalarnych (0, 1, 2)\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model(X_train.shape[1])\n",
    "\n",
    "#Krótki trening (Demo)\n",
    "print(\"Rozpoczęcie treningu modelu bazowego (Model 'Clean'):\")\n",
    "# Używamy verbose=0, aby wyciszyć szczegóły epok w notebooku\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=16,\n",
    "          validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "# Ocena modelu bazowego\n",
    "res_clean_base = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\n Dokładność modelu bazowego (Clean Test): {res_clean_base[1]:.4f}\")"
   ],
   "id": "888f5aa640d45285",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczęcie treningu modelu bazowego (Model 'Clean'):\n",
      "\n",
      " Dokładność modelu bazowego (Clean Test): 0.8667\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T18:23:33.280311Z",
     "start_time": "2025-11-11T18:23:33.274420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Funkcja generująca adwersarialny przykład (FGSM)\n",
    "def create_adversarial_example(model, input_data, input_label, epsilon, min_val, max_val):\n",
    "    \"\"\"\n",
    "    Generuje adwersarialny przykład (perturbed input) metodą FGSM.\n",
    "\n",
    "    input_data: 1D numpy array (skalowane cechy)\n",
    "    input_label: skalarna etykieta (int)\n",
    "    zwraca: 2D numpy array shape (1, n_features)\n",
    "    \"\"\"\n",
    "    # 1. Konwersja na tensor z wymiarem batch\n",
    "    x = tf.convert_to_tensor(input_data.reshape((1, -1)), dtype=tf.float32)\n",
    "    y = tf.convert_to_tensor([input_label], dtype=tf.int32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x)\n",
    "        preds = model(x)\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(y, preds)\n",
    "\n",
    "    grad = tape.gradient(loss, x)               # Obliczenie gradientu\n",
    "    signed_grad = tf.sign(grad).numpy()         # Znak gradientu\n",
    "\n",
    "    # 2. Generowanie przykładu adwersarialnego\n",
    "    adv = x.numpy() + epsilon * signed_grad     # x' = x + epsilon * sign(gradient)\n",
    "\n",
    "    # 3. Klippowanie do zakresu skalowanych danych\n",
    "    adv = np.clip(adv, min_val, max_val)\n",
    "    return adv\n",
    "\n"
   ],
   "id": "7fc261c86f965758",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T18:24:31.888201Z",
     "start_time": "2025-11-11T18:24:31.755021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Test na jednym przykładowym obrazie\n",
    "idx = 0\n",
    "orig = X_test[idx]\n",
    "orig_label = y_test[idx]\n",
    "epsilon_test = 0.8 # Siła ataku (epsilon)\n",
    "\n",
    "pred_orig = model.predict(orig.reshape(1, -1), verbose=0)\n",
    "# Używamy modelu bazowego do generowania ataku\n",
    "adv_example = create_adversarial_example(model, orig, orig_label, epsilon_test, min_val, max_val)\n",
    "pred_adv = model.predict(adv_example, verbose=0)\n",
    "\n",
    "print(\"== Test FGSM na pojedynczym przykładzie ==\")\n",
    "print(f\"Prawdziwa etykieta: {orig_label}\")\n",
    "print(f\"Oryginalna predykcja: {np.argmax(pred_orig)} (konf: {np.max(pred_orig):.3f})\")\n",
    "print(f\"Adwersarialna predykcja: {np.argmax(pred_adv)} (konf: {np.max(pred_adv):.3f})\")\n",
    "print(f\"Czy atak się powiódł? {np.argmax(pred_orig) != np.argmax(pred_adv)}\")"
   ],
   "id": "f27fc395fcb9bd84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Test FGSM na pojedynczym przykładzie ==\n",
      "Prawdziwa etykieta: 0\n",
      "Oryginalna predykcja: 0 (konf: 0.996)\n",
      "Adwersarialna predykcja: 1 (konf: 0.511)\n",
      "Czy atak się powiódł? True\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T18:25:39.380196Z",
     "start_time": "2025-11-11T18:25:39.173939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Wyszukiwanie przykładu o najniższej pewności\n",
    "min_confidence = 1.0\n",
    "best_idx_for_attack = -1\n",
    "predictions = model.predict(X_test, verbose=0)\n",
    "true_labels = y_test\n",
    "\n",
    "# Przeszukujemy cały zbiór testowy, by znaleźć najsłabszy punkt\n",
    "for i in range(len(X_test)):\n",
    "    pred = predictions[i]\n",
    "    confidence = np.max(pred)\n",
    "\n",
    "    # Warunek: model musi poprawnie sklasyfikować przykład ORAZ mieć najmniejszą pewność\n",
    "    if np.argmax(pred) == true_labels[i] and confidence < min_confidence:\n",
    "        min_confidence = confidence\n",
    "        best_idx_for_attack = i\n",
    "\n",
    "if best_idx_for_attack != -1:\n",
    "    idx = best_idx_for_attack\n",
    "    print(f\" Znaleziono najlepszy indeks dla ataku: {idx}\")\n",
    "    print(f\"   Prawdziwa etykieta: {y_test[idx]}\")\n",
    "    print(f\"   Pewność oryginalnej predykcji: {min_confidence:.4f}\")\n",
    "else:\n",
    "    # W rzadkich przypadkach, gdy wszystkie przykłady mają idealną pewność lub kod jest zły\n",
    "    idx = 0\n",
    "    print(f\"⚠️ Nie znaleziono idealnego słabego punktu. Używam indeksu domyślnego: {idx}\")\n",
    "\n",
    "#Przypisanie danych do testu\n",
    "orig = X_test[idx]\n",
    "orig_label = y_test[idx]\n",
    "\n",
    "#Parametry ataku\n",
    "epsilon_test = 0.5 # Zwiększamy epsilon, aby skompensować ewentualną trudność ataku\n",
    "\n",
    "#Predykcje i Generowanie Ataku\n",
    "pred_orig = model.predict(orig.reshape(1, -1), verbose=0)\n",
    "adv_example = create_adversarial_example(model, orig, orig_label, epsilon_test, min_val, max_val)\n",
    "pred_adv = model.predict(adv_example, verbose=0)\n",
    "\n",
    "#Wyniki Ataku\n",
    "print(\"\\n== Test FGSM na Słabym Punkcie ==\")\n",
    "print(f\"Prawdziwa etykieta: {orig_label}\")\n",
    "print(f\"Oryginalna predykcja: {np.argmax(pred_orig)} (konf: {np.max(pred_orig):.3f})\")\n",
    "print(f\"Adwersarialna predykcja: {np.argmax(pred_adv)} (konf: {np.max(pred_adv):.3f})\")\n",
    "print(f\"Czy atak się powiódł? {np.argmax(pred_orig) != np.argmax(pred_adv)}\")"
   ],
   "id": "59b6a022dd3acf36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Znaleziono najlepszy indeks dla ataku: 9\n",
      "   Prawdziwa etykieta: 1\n",
      "   Pewność oryginalnej predykcji: 0.4834\n",
      "\n",
      "== Test FGSM na Słabym Punkcie ==\n",
      "Prawdziwa etykieta: 1\n",
      "Oryginalna predykcja: 1 (konf: 0.483)\n",
      "Adwersarialna predykcja: 2 (konf: 0.793)\n",
      "Czy atak się powiódł? True\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
