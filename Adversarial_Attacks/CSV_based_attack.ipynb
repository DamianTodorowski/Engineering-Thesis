{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "#Importy i Przygotowanie Danych\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from keras import layers, models\n",
    "\n",
    "# Ustawienie seed dla powtarzalności\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"Wersja TensorFlow: {tf.__version__}\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Ładowanie danych (Iris)\n",
    "data = load_iris()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "\n",
    "X = df.drop(columns=['target']).values\n",
    "y = df['target'].values\n",
    "\n",
    "# Standaryzacja\n",
    "# Skalowanie jest kluczowe, aby cechy miały średnią 0 i odchylenie standardowe 1.\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Zakres danych po skalowaniu jest potrzebny do poprawnego \"klippowania\"\n",
    "# (przycinania) perturbacji adwersarialnych, aby zachować sensowne wartości.\n",
    "min_val, max_val = X_scaled.min(), X_scaled.max()\n",
    "print(f\"Zakres danych po skalowaniu: [{min_val:.3f}, {max_val:.3f}]\")\n",
    "\n",
    "# --- Podział na zbiory treningowy i testowy ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Kształt zbioru treningowego: {X_train.shape}\")"
   ],
   "id": "885e1ec1090ad2f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T18:24:49.011007Z",
     "start_time": "2026-01-16T18:24:46.267660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Prosta sieć MLP (Multilayer Perceptron)\n",
    "def create_model(input_dim):\n",
    "    \"\"\"Tworzy model MLP z dwiema warstwami ukrytymi.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        # Warstwa wyjściowa: 3 klasy, aktywacja softmax\n",
    "        layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy', # Używamy dla etykiet skalarnych (0, 1, 2)\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model(X_train.shape[1])\n",
    "\n",
    "#Krótki trening (Demo)\n",
    "print(\"Rozpoczęcie treningu modelu bazowego (Model 'Clean'):\")\n",
    "# Używamy verbose=0, aby wyciszyć szczegóły epok w notebooku\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=16,\n",
    "          validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "# Ocena modelu bazowego\n",
    "res_clean_base = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\n Dokładność modelu bazowego (Clean Test): {res_clean_base[1]:.4f}\")"
   ],
   "id": "888f5aa640d45285",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczęcie treningu modelu bazowego (Model 'Clean'):\n",
      "\n",
      " Dokładność modelu bazowego (Clean Test): 0.8667\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T18:24:54.453160Z",
     "start_time": "2026-01-16T18:24:54.435249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Funkcja generująca adwersarialny przykład (FGSM)\n",
    "def create_adversarial_example(model, input_data, input_label, epsilon, min_val, max_val):\n",
    "    \"\"\"\n",
    "    Generuje adwersarialny przykład (perturbed input) metodą FGSM.\n",
    "\n",
    "    input_data: 1D numpy array (skalowane cechy)\n",
    "    input_label: skalarna etykieta (int)\n",
    "    zwraca: 2D numpy array shape (1, n_features)\n",
    "    \"\"\"\n",
    "    # 1. Konwersja na tensor z wymiarem batch\n",
    "    x = tf.convert_to_tensor(input_data.reshape((1, -1)), dtype=tf.float32)\n",
    "    y = tf.convert_to_tensor([input_label], dtype=tf.int32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x)\n",
    "        preds = model(x)\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(y, preds)\n",
    "\n",
    "    grad = tape.gradient(loss, x)               # Obliczenie gradientu\n",
    "    signed_grad = tf.sign(grad).numpy()         # Znak gradientu\n",
    "\n",
    "    # 2. Generowanie przykładu adwersarialnego\n",
    "    adv = x.numpy() + epsilon * signed_grad     # x' = x + epsilon * sign(gradient)\n",
    "\n",
    "    # 3. Klippowanie do zakresu skalowanych danych\n",
    "    adv = np.clip(adv, min_val, max_val)\n",
    "    return adv\n",
    "\n"
   ],
   "id": "7fc261c86f965758",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T18:24:57.798837Z",
     "start_time": "2026-01-16T18:24:57.581289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Test na jednym przykładowym obrazie\n",
    "idx = 0\n",
    "orig = X_test[idx]\n",
    "orig_label = y_test[idx]\n",
    "epsilon_test = 0.8 # Siła ataku (epsilon)\n",
    "\n",
    "pred_orig = model.predict(orig.reshape(1, -1), verbose=0)\n",
    "# Używamy modelu bazowego do generowania ataku\n",
    "adv_example = create_adversarial_example(model, orig, orig_label, epsilon_test, min_val, max_val)\n",
    "pred_adv = model.predict(adv_example, verbose=0)\n",
    "\n",
    "print(\"== Test FGSM na pojedynczym przykładzie ==\")\n",
    "print(f\"Prawdziwa etykieta: {orig_label}\")\n",
    "print(f\"Oryginalna predykcja: {np.argmax(pred_orig)} (konf: {np.max(pred_orig):.3f})\")\n",
    "print(f\"Adwersarialna predykcja: {np.argmax(pred_adv)} (konf: {np.max(pred_adv):.3f})\")\n",
    "print(f\"Czy atak się powiódł? {np.argmax(pred_orig) != np.argmax(pred_adv)}\")"
   ],
   "id": "f27fc395fcb9bd84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Test FGSM na pojedynczym przykładzie ==\n",
      "Prawdziwa etykieta: 0\n",
      "Oryginalna predykcja: 0 (konf: 0.997)\n",
      "Adwersarialna predykcja: 1 (konf: 0.531)\n",
      "Czy atak się powiódł? True\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T18:25:00.228727Z",
     "start_time": "2026-01-16T18:24:59.942861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Wyszukiwanie przykładu o najniższej pewności\n",
    "min_confidence = 1.0\n",
    "best_idx_for_attack = -1\n",
    "predictions = model.predict(X_test, verbose=0)\n",
    "true_labels = y_test\n",
    "\n",
    "# Przeszukujemy cały zbiór testowy, by znaleźć najsłabszy punkt\n",
    "for i in range(len(X_test)):\n",
    "    pred = predictions[i]\n",
    "    confidence = np.max(pred)\n",
    "\n",
    "    # Warunek: model musi poprawnie sklasyfikować przykład ORAZ mieć najmniejszą pewność\n",
    "    if np.argmax(pred) == true_labels[i] and confidence < min_confidence:\n",
    "        min_confidence = confidence\n",
    "        best_idx_for_attack = i\n",
    "\n",
    "if best_idx_for_attack != -1:\n",
    "    idx = best_idx_for_attack\n",
    "    print(f\" Znaleziono najlepszy indeks dla ataku: {idx}\")\n",
    "    print(f\"   Prawdziwa etykieta: {y_test[idx]}\")\n",
    "    print(f\"   Pewność oryginalnej predykcji: {min_confidence:.4f}\")\n",
    "else:\n",
    "    # W rzadkich przypadkach, gdy wszystkie przykłady mają idealną pewność lub kod jest zły\n",
    "    idx = 0\n",
    "    print(f\"⚠️ Nie znaleziono idealnego słabego punktu. Używam indeksu domyślnego: {idx}\")\n",
    "\n",
    "#Przypisanie danych do testu\n",
    "orig = X_test[idx]\n",
    "orig_label = y_test[idx]\n",
    "\n",
    "#Parametry ataku\n",
    "epsilon_test = 0.5 # Zwiększamy epsilon, aby skompensować ewentualną trudność ataku\n",
    "\n",
    "#Predykcje i Generowanie Ataku\n",
    "pred_orig = model.predict(orig.reshape(1, -1), verbose=0)\n",
    "adv_example = create_adversarial_example(model, orig, orig_label, epsilon_test, min_val, max_val)\n",
    "pred_adv = model.predict(adv_example, verbose=0)\n",
    "\n",
    "#Wyniki Ataku\n",
    "print(\"\\n== Test FGSM na Słabym Punkcie ==\")\n",
    "print(f\"Prawdziwa etykieta: {orig_label}\")\n",
    "print(f\"Oryginalna predykcja: {np.argmax(pred_orig)} (konf: {np.max(pred_orig):.3f})\")\n",
    "print(f\"Adwersarialna predykcja: {np.argmax(pred_adv)} (konf: {np.max(pred_adv):.3f})\")\n",
    "print(f\"Czy atak się powiódł? {np.argmax(pred_orig) != np.argmax(pred_adv)}\")"
   ],
   "id": "59b6a022dd3acf36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Znaleziono najlepszy indeks dla ataku: 9\n",
      "   Prawdziwa etykieta: 1\n",
      "   Pewność oryginalnej predykcji: 0.4999\n",
      "\n",
      "== Test FGSM na Słabym Punkcie ==\n",
      "Prawdziwa etykieta: 1\n",
      "Oryginalna predykcja: 1 (konf: 0.500)\n",
      "Adwersarialna predykcja: 2 (konf: 0.872)\n",
      "Czy atak się powiódł? True\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "results_table_cell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T18:25:03.736534Z",
     "start_time": "2026-01-16T18:25:03.701941Z"
    }
   },
   "source": [
    "# Tabela z wynikami\n",
    "results_data = {\n",
    "    \"Metryka\": [\"Prawdziwa Etykieta\", \"Oryginalna Predykcja\", \"Adwersarialna Predykcja\", \"Sukces\"],\n",
    "    \"Wartość\": [\n",
    "        orig_label,\n",
    "        f\"{np.argmax(pred_orig)} (pewność: {np.max(pred_orig):.3f})\",\n",
    "        f\"{np.argmax(pred_adv)} (pewność: {np.max(pred_adv):.3f})\",\n",
    "        \"TAK\" if np.argmax(pred_orig) != np.argmax(pred_adv) else \"NIE\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_results = pd.DataFrame(results_data)\n",
    "print(\"\\n=== Podsumowanie Ataku ===\")\n",
    "display(df_results)\n",
    "\n",
    "# Porównanie cech (odwrócenie skalowania)\n",
    "orig_real = scaler.inverse_transform(orig.reshape(1, -1))[0]\n",
    "adv_real = scaler.inverse_transform(adv_example)[0]\n",
    "\n",
    "# Tłumaczenie nazw cech\n",
    "feature_map = {\n",
    "    \"sepal length (cm)\": \"długość działki kielicha (cm)\",\n",
    "    \"sepal width (cm)\": \"szerokość działki kielicha (cm)\",\n",
    "    \"petal length (cm)\": \"długość płatka (cm)\",\n",
    "    \"petal width (cm)\": \"szerokość płatka (cm)\"\n",
    "}\n",
    "polish_features = [feature_map.get(f, f) for f in data.feature_names]\n",
    "\n",
    "feature_comparison = {\n",
    "    \"Cecha\": polish_features,\n",
    "    \"Oryginał\": list(orig_real),\n",
    "    \"Adwersarialne\": list(adv_real),\n",
    "    \"Różnica\": list(adv_real - orig_real)\n",
    "}\n",
    "\n",
    "df_features = pd.DataFrame(feature_comparison)\n",
    "\n",
    "# Dodanie wiersza z klasyfikacją (Gatunek)\n",
    "class_names = data.target_names\n",
    "idx_orig = np.argmax(pred_orig)\n",
    "idx_adv = np.argmax(pred_adv)\n",
    "\n",
    "new_row = {\n",
    "    \"Cecha\": \"PREDYKCJA (Gatunek)\",\n",
    "    \"Oryginał\": f\"{idx_orig} ({class_names[idx_orig]})\",\n",
    "    \"Adwersarialne\": f\"{idx_adv} ({class_names[idx_adv]})\",\n",
    "    \"Różnica\": \"PORAŻKA\" if idx_orig == idx_adv else \"SUKCES\"\n",
    "}\n",
    "\n",
    "# Append new row using pd.concat to avoid FutureWarning\n",
    "df_features = pd.concat([df_features, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "print(\"\\n=== Porównanie Cech (Wartości Rzeczywiste) ===\")\n",
    "display(df_features)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Podsumowanie Ataku ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                   Metryka             Wartość\n",
       "0       Prawdziwa Etykieta                   1\n",
       "1     Oryginalna Predykcja  1 (pewność: 0.500)\n",
       "2  Adwersarialna Predykcja  2 (pewność: 0.872)\n",
       "3                   Sukces                 TAK"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metryka</th>\n",
       "      <th>Wartość</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prawdziwa Etykieta</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oryginalna Predykcja</td>\n",
       "      <td>1 (pewność: 0.500)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adwersarialna Predykcja</td>\n",
       "      <td>2 (pewność: 0.872)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sukces</td>\n",
       "      <td>TAK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Porównanie Cech (Wartości Rzeczywiste) ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                             Cecha        Oryginał  Adwersarialne   Różnica\n",
       "0    długość działki kielicha (cm)             5.4       5.812651  0.412651\n",
       "1  szerokość działki kielicha (cm)             3.0       3.217205  0.217205\n",
       "2              długość płatka (cm)             4.5       5.379702  0.879702\n",
       "3            szerokość płatka (cm)             1.5       1.879846  0.379846\n",
       "4              PREDYKCJA (Gatunek)  1 (versicolor)  2 (virginica)    SUKCES"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cecha</th>\n",
       "      <th>Oryginał</th>\n",
       "      <th>Adwersarialne</th>\n",
       "      <th>Różnica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>długość działki kielicha (cm)</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.812651</td>\n",
       "      <td>0.412651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>szerokość działki kielicha (cm)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.217205</td>\n",
       "      <td>0.217205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>długość płatka (cm)</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.379702</td>\n",
       "      <td>0.879702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>szerokość płatka (cm)</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.879846</td>\n",
       "      <td>0.379846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PREDYKCJA (Gatunek)</td>\n",
       "      <td>1 (versicolor)</td>\n",
       "      <td>2 (virginica)</td>\n",
       "      <td>SUKCES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T18:25:08.199672Z",
     "start_time": "2026-01-16T18:25:07.838893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === PODSUMOWANIE I TABELA PORÓWNAWCZA ===\n",
    "\n",
    "# 1. Konfiguracja parametrów oceny\n",
    "epsilon_eval = 0.5  # Siła ataku dla ewaluacji (możesz zmienić np. na 0.2 lub 0.8)\n",
    "print(f\"Generowanie zbioru adwersarialnego dla całego zbioru testowego (epsilon={epsilon_eval})...\")\n",
    "\n",
    "# 2. Generowanie danych adwersarialnych dla całego X_test\n",
    "X_test_adv_list = []\n",
    "for i in range(len(X_test)):\n",
    "    # Używamy zdefiniowanej wcześniej funkcji create_adversarial_example\n",
    "    # Upewnij się, że min_val i max_val są zdefiniowane (z komórki 1)\n",
    "    adv_sample = create_adversarial_example(model, X_test[i], y_test[i], epsilon_eval, min_val, max_val)\n",
    "    X_test_adv_list.append(adv_sample)\n",
    "\n",
    "# Łączenie listy w jedną macierz numpy\n",
    "X_test_adv = np.vstack(X_test_adv_list)\n",
    "\n",
    "# 3. Ewaluacja modelu\n",
    "# Wyniki na czystych danych\n",
    "loss_clean, acc_clean = model.evaluate(X_test, y_test, verbose=0)\n",
    "# Wyniki na danych adwersarialnych\n",
    "loss_adv, acc_adv = model.evaluate(X_test_adv, y_test, verbose=0)\n",
    "\n",
    "# Obliczenie liczby poprawnych próbek\n",
    "correct_clean = int(acc_clean * len(X_test))\n",
    "correct_adv = int(acc_adv * len(X_test))\n",
    "\n",
    "# 4. Tworzenie tabeli wyników\n",
    "comparison_data = {\n",
    "    \"Metryka\": [\"Dokładność (Accuracy)\", \"Strata (Loss)\", \"Poprawne Próbki (na 30)\"],\n",
    "    \"Czyste Dane\": [\n",
    "        f\"{acc_clean:.4f}\",\n",
    "        f\"{loss_clean:.4f}\",\n",
    "        f\"{correct_clean}/{len(X_test)}\"\n",
    "    ],\n",
    "    f\"Dane Adwersarialne (eps={epsilon_eval})\": [\n",
    "        f\"{acc_adv:.4f}\",\n",
    "        f\"{loss_adv:.4f}\",\n",
    "        f\"{correct_adv}/{len(X_test)}\"\n",
    "    ],\n",
    "    \"Różnica (Wpływ ataku)\": [\n",
    "        f\"{(acc_adv - acc_clean):.4f}\",\n",
    "        f\"{(loss_adv - loss_clean):.4f}\",\n",
    "        f\"{correct_adv - correct_clean}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "\n",
    "# Wyświetlenie tabeli\n",
    "print(\"\\n=== TABELA PORÓWNAWCZA: MODEL BAZOWY VS ATAK FGSM ===\")\n",
    "from IPython.display import display\n",
    "display(df_comparison)\n",
    "\n",
    "# Opcjonalnie: Obliczenie skuteczności ataku (Attack Success Rate - ile próbek zmieniło klasyfikację na błędną)\n",
    "print(f\"\\nSkuteczność ataku (spadek accuracy): {(acc_clean - acc_adv)*100:.2f} p.p.\")"
   ],
   "id": "22afb63d8d7ee0ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generowanie zbioru adwersarialnego dla całego zbioru testowego (epsilon=0.5)...\n",
      "\n",
      "=== TABELA PORÓWNAWCZA: MODEL BAZOWY VS ATAK FGSM ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                   Metryka Czyste Dane Dane Adwersarialne (eps=0.5)  \\\n",
       "0    Dokładność (Accuracy)      0.8667                       0.5667   \n",
       "1            Strata (Loss)      0.2559                       0.9807   \n",
       "2  Poprawne Próbki (na 30)       26/30                        16/30   \n",
       "\n",
       "  Różnica (Wpływ ataku)  \n",
       "0               -0.3000  \n",
       "1                0.7249  \n",
       "2                   -10  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metryka</th>\n",
       "      <th>Czyste Dane</th>\n",
       "      <th>Dane Adwersarialne (eps=0.5)</th>\n",
       "      <th>Różnica (Wpływ ataku)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dokładność (Accuracy)</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>0.5667</td>\n",
       "      <td>-0.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Strata (Loss)</td>\n",
       "      <td>0.2559</td>\n",
       "      <td>0.9807</td>\n",
       "      <td>0.7249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Poprawne Próbki (na 30)</td>\n",
       "      <td>26/30</td>\n",
       "      <td>16/30</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skuteczność ataku (spadek accuracy): 30.00 p.p.\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
