{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atak adwersarialny na filtr spamu przy użyciu TextAttack\n",
    "\n",
    "Ten notatnik demonstruje, jak przeprowadzić atak zwodniczy na model wykrywania spamu przy użyciu biblioteki `textattack`. Użyjemy przepisu ataku `TextBugger` przeciwko filtrowi spamu opartemu na BERT-Tiny."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T19:39:23.476537Z",
     "start_time": "2026-01-24T19:39:23.459194Z"
    }
   },
   "source": [
    "# Importowanie niezbędnych bibliotek\n",
    "import textattack\n",
    "import transformers\n",
    "from textattack.models.wrappers import HuggingFaceModelWrapper\n",
    "from textattack.datasets import HuggingFaceDataset\n",
    "from textattack.attack_recipes import TextFoolerJin2019, TextBuggerLi2018, DeepWordBugGao2018\n",
    "from textattack import Attacker\n",
    "from textattack.loggers import CSVLogger\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# textattack: Główna biblioteka do ataków adwersarzowych.\n",
    "# transformers: Biblioteka Hugging Face do modeli NLP.\n",
    "# HuggingFaceModelWrapper: Wrapper, który pozwala TextAttack korzystać z modeli Hugging Face.\n",
    "# HuggingFaceDataset: Klasa do ładowania zbiorów danych z Hugging Face.\n",
    "# TextFoolerJin2019, TextBuggerLi2018, DeepWordBugGao2018: Gotowe przepisy (recipes) ataków.\n",
    "# Attacker: Klasa zarządzająca procesem ataku.\n",
    "# CSVLogger: Do zapisywania wyników w pliku CSV."
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ładowanie modelu i tokenizera\n",
    "\n",
    "Użyjemy `mrm8488/bert-tiny-finetuned-sms-spam-detection`, modelu BERT-Tiny dostrojonego na zbiorze danych SMS Spam. Ten model jest stosunkowo mały i dosyć podatny na ataki."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T19:39:27.575193Z",
     "start_time": "2026-01-24T19:39:25.477819Z"
    }
   },
   "source": [
    "# Nazwa modelu do pobrania z Hugging Face Hub\n",
    "model_name = \"mrm8488/bert-tiny-finetuned-sms-spam-detection\"\n",
    "\n",
    "# Załadowanie modelu klasyfikacji sekwencji\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "# Załadowanie tokenizera odpowiadającego modelowi\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Opakowanie modelu i tokenizera w wrapper TextAttack, aby biblioteka mogła z nich korzystać\n",
    "model_wrapper = HuggingFaceModelWrapper(model, tokenizer)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Załadowanie zbioru danych\n",
    "\n",
    "Użyjemy zbioru danych `sms_spam` z biblioteki `datasets` Hugging Face. Uwaga: `sms_spam` zawiera tylko podział 'train', więc go użyjemy."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T19:39:33.609732Z",
     "start_time": "2026-01-24T19:39:29.383268Z"
    }
   },
   "source": [
    "# Załaduj zbiór danych (sms_spam ma tylko podział 'train')\n",
    "# Musimy również określić kolumny zbioru danych, ponieważ textattack nie rozpoznaje automatycznie 'sms' jako kolumny wejściowej\n",
    "dataset = HuggingFaceDataset(\"sms_spam\", split=\"train\", shuffle=True, dataset_columns=(['sms'], 'label'))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Loading \u001B[94mdatasets\u001B[0m dataset \u001B[94msms_spam\u001B[0m, split \u001B[94mtrain\u001B[0m.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.  Definicja Ataków Przeciwnych (Adversarial Attacks)\n",
    "\n",
    "W tej analizie skupimy się na trzech metodach generowania przeciwnych przykładów tekstowych. Użyjemy **TextBugger** (`TextBuggerLi2018`) jako głównego ataku, a **TextFooler** i **DeepWordBug** jako alternatyw porównawczych.\n",
    "\n",
    "---\n",
    "\n",
    "## 3.1. Główny Atak: TextBugger (`TextBuggerLi2018`)\n",
    "\n",
    "TextBugger jest **hybrydowym** atakiem typu **black-box**, zaprojektowanym do wprowadzania **minimalnych, zrozumiałych perturbacji** (zwanych \"bugami\") do tekstu. Jego celem jest spowodowanie błędnej klasyfikacji przez model docelowy przy jednoczesnym zachowaniu *utility* (zrozumiałości i użyteczności) dla ludzkiego oka.\n",
    "\n",
    "###  Mechanizm działania\n",
    "\n",
    "1.  **Identyfikacja Krytycznych Słów:** Atak najpierw wybiera słowa, które mają **największy wpływ** na pierwotną klasyfikację, mierząc spadek pewności modelu po ich usunięciu.\n",
    "2.  **Generowanie Perturbacji (Bugów):** Dla każdego krytycznego słowa generowane są kandydatury zmian na dwóch poziomach:\n",
    "\n",
    "| Poziom | Typ Perturbacji | Opis | Przykład (`love`) |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Słowo (Word)** | Podstawianie (Sub-W) | Zastąpienie słowa **synonimem** lub semantycznie bliskim sąsiadem (z wektorów embeddings lub WordNet). | `love` $\\rightarrow$ `affection` |\n",
    "| **Znak (Character)** | Wstawianie (Insert-C) | Wstawienie losowej litery lub spacji wewnątrz słowa. | `love` $\\rightarrow$ `l ove` |\n",
    "| **Znak (Character)** | Zamiana (Swap-C) | Zamiana sąsiednich znaków wewnątrz słowa. | `love` $\\rightarrow$ `lvoe` |\n",
    "| **Znak (Character)** | Podstawianie (Sub-C) | Zastąpienie znaku wizualnie podobnym (np. **homoglify**) lub sąsiadem z klawiatury. | `love` $\\rightarrow$ `lovd` |\n",
    "\n",
    "3.  **Optymalizacja:** Wybierany jest kandydat, który **maksymalnie zmienia predykcję** na błędną klasę, jednocześnie minimalizując liczbę użytych modyfikacji.\n",
    "\n",
    "---\n",
    "\n",
    "## 3.2. Alternatywne Ataki Porównawcze\n",
    "\n",
    "Importujemy również `TextFooler` i `DeepWordBug` jako alternatywne strategie ataku, które różnią się metodologią perturbacji.\n",
    "\n",
    "###  TextFooler (`TextFoolerJin2020`)\n",
    "\n",
    "* **Charakterystyka:** Atak koncentrujący się wyłącznie na **podmianie słów** przy użyciu **synonimów**.\n",
    "* **Kluczowa Cecha:** Po wybraniu krytycznych słów, synonimy są filtrowane przez **Universal Sentence Encoder (USE)**, aby zapewnić, że nowy tekst ma to samo znaczenie (zachowanie wysokiego podobieństwa semantycznego). Jest to kluczowe dla zachowania płynności i sensu zdania.\n",
    "\n",
    "###  DeepWordBug (`DeepWordBugGao2018`)\n",
    "\n",
    "* **Charakterystyka:** Atak skupiający się wyłącznie na **perturbacjach na poziomie znaków** (literówki), wykorzystujący bardziej zaawansowany mechanizm wyboru celu.\n",
    "* **Kluczowa Cecha:** Jest to atak typu **white-box**, który wymaga dostępu do **gradientów** modelu. Używa techniki **Backward Differentiation** do obliczenia, które słowa są **najbardziej wrażliwe** na małe zmiany w swoich znakach, a następnie celuje w te znaki, aby maksymalnie zwiększyć stratę modelu."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T19:39:36.422966Z",
     "start_time": "2026-01-24T19:39:36.407098Z"
    }
   },
   "source": [
    "# Wybierz przepis ataku (attack recipe)\n",
    "attack_recipe = \"TextBugger\"\n",
    "\n",
    "if attack_recipe == \"TextBugger\":\n",
    "    # Zbuduj atak TextBugger dla naszego modelu\n",
    "    attack = TextBuggerLi2018.build(model_wrapper)\n",
    "elif attack_recipe == \"TextFooler\":\n",
    "    # Zbuduj atak TextFooler\n",
    "    attack = TextFoolerJin2019.build(model_wrapper)\n",
    "elif attack_recipe == \"DeepWordBug\":\n",
    "    # Zbuduj atak DeepWordBug\n",
    "    attack = DeepWordBugGao2018.build(model_wrapper)\n",
    "\n",
    "print(f\"Używany przepis ataku: {attack_recipe}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Używany przepis ataku: TextBugger\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Uruchomienie ataku\n",
    "\n",
    "Uruchomimy atak na 10 przykładach, aby zademonstrować jego skuteczność. Zapiszemy również wyniki do wizualizacji."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T19:49:45.905168Z",
     "start_time": "2026-01-24T19:39:39.861887Z"
    }
   },
   "source": [
    "# Atakuj 10 próbek\n",
    "# AttackArgs: argumenty dla ataku, takie jak liczba przykładów i logowanie do CSV\n",
    "attack_args = textattack.AttackArgs(num_examples=10, log_to_csv=\"results_spam.csv\")\n",
    "# Attacker: obiekt wykonujący atak na zbiorze danych\n",
    "attacker = Attacker(attack, dataset, attack_args)\n",
    "# Uruchomienie ataku i pobranie wyników\n",
    "results = attacker.attack_dataset()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Logging to CSV at path results_spam.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  delete\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  CompositeTransformation(\n",
      "    (0): WordSwapRandomCharacterInsertion(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    (1): WordSwapRandomCharacterDeletion(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    (2): WordSwapNeighboringCharacterSwap(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    (3): WordSwapHomoglyphSwap\n",
      "    (4): WordSwapEmbedding(\n",
      "        (max_candidates):  5\n",
      "        (embedding):  WordEmbedding\n",
      "      )\n",
      "    )\n",
      "  (constraints): \n",
      "    (0): UniversalSentenceEncoder(\n",
      "        (metric):  angular\n",
      "        (threshold):  0.8\n",
      "        (window_size):  inf\n",
      "        (skip_text_shorter_than_window):  False\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): RepeatModification\n",
      "    (2): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m attacker \u001B[38;5;241m=\u001B[39m Attacker(attack, dataset, attack_args)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# Uruchomienie ataku i pobranie wyników\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mattacker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattack_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Engieering Thesis\\Adversarial_Attacks\\.venv\\lib\\site-packages\\textattack\\attacker.py:441\u001B[0m, in \u001B[0;36mAttacker.attack_dataset\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    439\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_attack_parallel()\n\u001B[0;32m    440\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 441\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_attack\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    443\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattack_args\u001B[38;5;241m.\u001B[39msilent:\n\u001B[0;32m    444\u001B[0m     logger\u001B[38;5;241m.\u001B[39msetLevel(logging\u001B[38;5;241m.\u001B[39mINFO)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Engieering Thesis\\Adversarial_Attacks\\.venv\\lib\\site-packages\\textattack\\attacker.py:168\u001B[0m, in \u001B[0;36mAttacker._attack\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    166\u001B[0m     example\u001B[38;5;241m.\u001B[39mattack_attrs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabel_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39mlabel_names\n\u001B[0;32m    167\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 168\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattack\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mground_truth_output\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    169\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    170\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Engieering Thesis\\Adversarial_Attacks\\.venv\\lib\\site-packages\\textattack\\attack.py:450\u001B[0m, in \u001B[0;36mAttack.attack\u001B[1;34m(self, example, ground_truth_output)\u001B[0m\n\u001B[0;32m    448\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m SkippedAttackResult(goal_function_result)\n\u001B[0;32m    449\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 450\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_attack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgoal_function_result\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    451\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Engieering Thesis\\Adversarial_Attacks\\.venv\\lib\\site-packages\\textattack\\attack.py:398\u001B[0m, in \u001B[0;36mAttack._attack\u001B[1;34m(self, initial_result)\u001B[0m\n\u001B[0;32m    387\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_attack\u001B[39m(\u001B[38;5;28mself\u001B[39m, initial_result):\n\u001B[0;32m    388\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Calls the ``SearchMethod`` to perturb the ``AttackedText`` stored in\u001B[39;00m\n\u001B[0;32m    389\u001B[0m \u001B[38;5;124;03m    ``initial_result``.\u001B[39;00m\n\u001B[0;32m    390\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    396\u001B[0m \u001B[38;5;124;03m            or ``MaximizedAttackResult``.\u001B[39;00m\n\u001B[0;32m    397\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 398\u001B[0m     final_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43minitial_result\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    399\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclear_cache()\n\u001B[0;32m    400\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m final_result\u001B[38;5;241m.\u001B[39mgoal_status \u001B[38;5;241m==\u001B[39m GoalFunctionResultStatus\u001B[38;5;241m.\u001B[39mSUCCEEDED:\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Engieering Thesis\\Adversarial_Attacks\\.venv\\lib\\site-packages\\textattack\\search_methods\\search_method.py:35\u001B[0m, in \u001B[0;36mSearchMethod.__call__\u001B[1;34m(self, initial_result)\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfilter_transformations\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m     31\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[0;32m     32\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSearch Method must have access to filter_transformations method\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     33\u001B[0m     )\n\u001B[1;32m---> 35\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mperform_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43minitial_result\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;66;03m# ensure that the number of queries for this GoalFunctionResult is up-to-date\u001B[39;00m\n\u001B[0;32m     37\u001B[0m result\u001B[38;5;241m.\u001B[39mnum_queries \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgoal_function\u001B[38;5;241m.\u001B[39mnum_queries\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Engieering Thesis\\Adversarial_Attacks\\.venv\\lib\\site-packages\\textattack\\search_methods\\greedy_word_swap_wir.py:141\u001B[0m, in \u001B[0;36mGreedyWordSwapWIR.perform_search\u001B[1;34m(self, initial_result)\u001B[0m\n\u001B[0;32m    139\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    140\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m i \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mlen\u001B[39m(index_order) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m search_over:\n\u001B[1;32m--> 141\u001B[0m     transformed_text_candidates \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_transformations\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    142\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcur_result\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattacked_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    143\u001B[0m \u001B[43m        \u001B[49m\u001B[43moriginal_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitial_result\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattacked_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    144\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindices_to_modify\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mindex_order\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    145\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    146\u001B[0m     i \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    147\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(transformed_text_candidates) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Engieering Thesis\\Adversarial_Attacks\\.venv\\lib\\site-packages\\textattack\\attack.py:315\u001B[0m, in \u001B[0;36mAttack.get_transformations\u001B[1;34m(self, current_text, original_text, **kwargs)\u001B[0m\n\u001B[0;32m    310\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    311\u001B[0m     transformed_texts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_transformations_uncached(\n\u001B[0;32m    312\u001B[0m         current_text, original_text, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    313\u001B[0m     )\n\u001B[1;32m--> 315\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilter_transformations\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    316\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtransformed_texts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcurrent_text\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moriginal_text\u001B[49m\n\u001B[0;32m    317\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Engieering Thesis\\Adversarial_Attacks\\.venv\\lib\\site-packages\\textattack\\attack.py:380\u001B[0m, in \u001B[0;36mAttack.filter_transformations\u001B[1;34m(self, transformed_texts, current_text, original_text)\u001B[0m\n\u001B[0;32m    378\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconstraints_cache[(current_text, transformed_text)]:\n\u001B[0;32m    379\u001B[0m             filtered_texts\u001B[38;5;241m.\u001B[39mappend(transformed_text)\n\u001B[1;32m--> 380\u001B[0m filtered_texts \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_filter_transformations_uncached\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    381\u001B[0m \u001B[43m    \u001B[49m\u001B[43muncached_texts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcurrent_text\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moriginal_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moriginal_text\u001B[49m\n\u001B[0;32m    382\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    383\u001B[0m \u001B[38;5;66;03m# Sort transformations to ensure order is preserved between runs\u001B[39;00m\n\u001B[0;32m    384\u001B[0m filtered_texts\u001B[38;5;241m.\u001B[39msort(key\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m t: t\u001B[38;5;241m.\u001B[39mtext)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Engieering Thesis\\Adversarial_Attacks\\.venv\\lib\\site-packages\\textattack\\attack.py:340\u001B[0m, in \u001B[0;36mAttack._filter_transformations_uncached\u001B[1;34m(self, transformed_texts, current_text, original_text)\u001B[0m\n\u001B[0;32m    335\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m original_text:\n\u001B[0;32m    336\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    337\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing `original_text` argument when constraint \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(C)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is set to compare against `original_text`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    338\u001B[0m         )\n\u001B[1;32m--> 340\u001B[0m     filtered_texts \u001B[38;5;241m=\u001B[39m \u001B[43mC\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_many\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfiltered_texts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moriginal_text\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    341\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    342\u001B[0m     filtered_texts \u001B[38;5;241m=\u001B[39m C\u001B[38;5;241m.\u001B[39mcall_many(filtered_texts, current_text)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Engieering Thesis\\Adversarial_Attacks\\.venv\\lib\\site-packages\\textattack\\constraints\\constraint.py:50\u001B[0m, in \u001B[0;36mConstraint.call_many\u001B[1;34m(self, transformed_texts, reference_text)\u001B[0m\n\u001B[0;32m     46\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n\u001B[0;32m     47\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\n\u001B[0;32m     48\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtransformed_text must have `last_transformation` attack_attr to apply constraint\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     49\u001B[0m         )\n\u001B[1;32m---> 50\u001B[0m filtered_texts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_constraint_many\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     51\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompatible_transformed_texts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreference_text\u001B[49m\n\u001B[0;32m     52\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(filtered_texts) \u001B[38;5;241m+\u001B[39m incompatible_transformed_texts\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Engieering Thesis\\Adversarial_Attacks\\.venv\\lib\\site-packages\\textattack\\constraints\\semantics\\sentence_encoders\\sentence_encoder.py:179\u001B[0m, in \u001B[0;36mSentenceEncoder._check_constraint_many\u001B[1;34m(self, transformed_texts, reference_text)\u001B[0m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_check_constraint_many\u001B[39m(\u001B[38;5;28mself\u001B[39m, transformed_texts, reference_text):\n\u001B[0;32m    176\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Filters the list ``transformed_texts`` so that the similarity\u001B[39;00m\n\u001B[0;32m    177\u001B[0m \u001B[38;5;124;03m    between the ``reference_text`` and the transformed text is greater than\u001B[39;00m\n\u001B[0;32m    178\u001B[0m \u001B[38;5;124;03m    the ``self.threshold``.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 179\u001B[0m     scores \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_score_list\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreference_text\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransformed_texts\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    181\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, transformed_text \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(transformed_texts):\n\u001B[0;32m    182\u001B[0m         \u001B[38;5;66;03m# Optionally ignore similarity score for sentences shorter than the\u001B[39;00m\n\u001B[0;32m    183\u001B[0m         \u001B[38;5;66;03m# window size.\u001B[39;00m\n\u001B[0;32m    184\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    185\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mskip_text_shorter_than_window\n\u001B[0;32m    186\u001B[0m             \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(transformed_text\u001B[38;5;241m.\u001B[39mwords) \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwindow_size\n\u001B[0;32m    187\u001B[0m         ):\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Engieering Thesis\\Adversarial_Attacks\\.venv\\lib\\site-packages\\textattack\\constraints\\semantics\\sentence_encoders\\sentence_encoder.py:152\u001B[0m, in \u001B[0;36mSentenceEncoder._score_list\u001B[1;34m(self, starting_text, transformed_texts)\u001B[0m\n\u001B[0;32m    142\u001B[0m     starting_text_windows\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m    143\u001B[0m         starting_text\u001B[38;5;241m.\u001B[39mtext_window_around_index(\n\u001B[0;32m    144\u001B[0m             modified_index, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwindow_size\n\u001B[0;32m    145\u001B[0m         )\n\u001B[0;32m    146\u001B[0m     )\n\u001B[0;32m    147\u001B[0m     transformed_text_windows\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m    148\u001B[0m         transformed_text\u001B[38;5;241m.\u001B[39mtext_window_around_index(\n\u001B[0;32m    149\u001B[0m             modified_index, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwindow_size\n\u001B[0;32m    150\u001B[0m         )\n\u001B[0;32m    151\u001B[0m     )\n\u001B[1;32m--> 152\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstarting_text_windows\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtransformed_text_windows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    153\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(embeddings, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[0;32m    154\u001B[0m     embeddings \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(embeddings)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Engieering Thesis\\Adversarial_Attacks\\.venv\\lib\\site-packages\\textattack\\constraints\\semantics\\sentence_encoders\\universal_sentence_encoder\\universal_sentence_encoder.py:30\u001B[0m, in \u001B[0;36mUniversalSentenceEncoder.encode\u001B[1;34m(self, sentences)\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mencode\u001B[39m(\u001B[38;5;28mself\u001B[39m, sentences):\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel:\n\u001B[1;32m---> 30\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[43mhub\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tfhub_url\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     31\u001B[0m     encoding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(sentences)\n\u001B[0;32m     33\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(encoding, \u001B[38;5;28mdict\u001B[39m):\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Engieering Thesis\\Adversarial_Attacks\\.venv\\lib\\site-packages\\tensorflow_hub\\module_v2.py:100\u001B[0m, in \u001B[0;36mload\u001B[1;34m(handle, tags, options)\u001B[0m\n\u001B[0;32m     98\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m     99\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected a string, got \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m handle)\n\u001B[1;32m--> 100\u001B[0m module_path \u001B[38;5;241m=\u001B[39m \u001B[43mresolve\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    101\u001B[0m is_hub_module_v1 \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mgfile\u001B[38;5;241m.\u001B[39mexists(_get_module_proto_path(module_path))\n\u001B[0;32m    102\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tags \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m is_hub_module_v1:\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Engieering Thesis\\Adversarial_Attacks\\.venv\\lib\\site-packages\\tensorflow_hub\\module_v2.py:55\u001B[0m, in \u001B[0;36mresolve\u001B[1;34m(handle)\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mresolve\u001B[39m(handle):\n\u001B[0;32m     32\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Resolves a module handle into a path.\u001B[39;00m\n\u001B[0;32m     33\u001B[0m \n\u001B[0;32m     34\u001B[0m \u001B[38;5;124;03m  This function works both for plain TF2 SavedModels and the legacy TF1 Hub\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;124;03m    A string representing the Module path.\u001B[39;00m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[1;32m---> 55\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mregistry\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresolver\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Engieering Thesis\\Adversarial_Attacks\\.venv\\lib\\site-packages\\tensorflow_hub\\registry.py:49\u001B[0m, in \u001B[0;36mMultiImplRegister.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m impl \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mreversed\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_impls):\n\u001B[0;32m     48\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m impl\u001B[38;5;241m.\u001B[39mis_supported(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 49\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     50\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m     fails\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mtype\u001B[39m(impl)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Engieering Thesis\\Adversarial_Attacks\\.venv\\lib\\site-packages\\tensorflow_hub\\compressed_module_resolver.py:81\u001B[0m, in \u001B[0;36mHttpCompressedFileResolver.__call__\u001B[1;34m(self, handle)\u001B[0m\n\u001B[0;32m     77\u001B[0m   response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_urlopen(request)\n\u001B[0;32m     78\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m resolver\u001B[38;5;241m.\u001B[39mDownloadManager(handle)\u001B[38;5;241m.\u001B[39mdownload_and_uncompress(\n\u001B[0;32m     79\u001B[0m       response, tmp_dir)\n\u001B[1;32m---> 81\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mresolver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43matomic_download\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdownload\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodule_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     82\u001B[0m \u001B[43m                                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_lock_file_timeout_sec\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Engieering Thesis\\Adversarial_Attacks\\.venv\\lib\\site-packages\\tensorflow_hub\\resolver.py:421\u001B[0m, in \u001B[0;36matomic_download\u001B[1;34m(handle, download_fn, module_dir, lock_file_timeout_sec)\u001B[0m\n\u001B[0;32m    419\u001B[0m logging\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDownloading TF-Hub Module \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, handle)\n\u001B[0;32m    420\u001B[0m tf\u001B[38;5;241m.\u001B[39mcompat\u001B[38;5;241m.\u001B[39mv1\u001B[38;5;241m.\u001B[39mgfile\u001B[38;5;241m.\u001B[39mMakeDirs(tmp_dir)\n\u001B[1;32m--> 421\u001B[0m \u001B[43mdownload_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtmp_dir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    422\u001B[0m \u001B[38;5;66;03m# Write module descriptor to capture information about which module was\u001B[39;00m\n\u001B[0;32m    423\u001B[0m \u001B[38;5;66;03m# downloaded by whom and when. The file stored at the same level as a\u001B[39;00m\n\u001B[0;32m    424\u001B[0m \u001B[38;5;66;03m# directory in order to keep the content of the 'model_dir' exactly as it\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    429\u001B[0m \u001B[38;5;66;03m# module caching protocol and no code in the TF-Hub library reads its\u001B[39;00m\n\u001B[0;32m    430\u001B[0m \u001B[38;5;66;03m# content.\u001B[39;00m\n\u001B[0;32m    431\u001B[0m _write_module_descriptor_file(handle, module_dir)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Engieering Thesis\\Adversarial_Attacks\\.venv\\lib\\site-packages\\tensorflow_hub\\compressed_module_resolver.py:78\u001B[0m, in \u001B[0;36mHttpCompressedFileResolver.__call__.<locals>.download\u001B[1;34m(handle, tmp_dir)\u001B[0m\n\u001B[0;32m     75\u001B[0m request \u001B[38;5;241m=\u001B[39m urllib\u001B[38;5;241m.\u001B[39mrequest\u001B[38;5;241m.\u001B[39mRequest(\n\u001B[0;32m     76\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_append_compressed_format_query(handle))\n\u001B[0;32m     77\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_urlopen(request)\n\u001B[1;32m---> 78\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mresolver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDownloadManager\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload_and_uncompress\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     79\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtmp_dir\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Engieering Thesis\\Adversarial_Attacks\\.venv\\lib\\site-packages\\tensorflow_hub\\resolver.py:192\u001B[0m, in \u001B[0;36mDownloadManager.download_and_uncompress\u001B[1;34m(self, fileobj, dst_path)\u001B[0m\n\u001B[0;32m    182\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Streams the content for the 'fileobj' and stores the result in dst_path.\u001B[39;00m\n\u001B[0;32m    183\u001B[0m \n\u001B[0;32m    184\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    189\u001B[0m \u001B[38;5;124;03m  ValueError: Unknown object encountered inside the TAR file.\u001B[39;00m\n\u001B[0;32m    190\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    191\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 192\u001B[0m   \u001B[43mfile_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextract_tarfile_to_destination\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    193\u001B[0m \u001B[43m      \u001B[49m\u001B[43mfileobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdst_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_function\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_log_progress\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    194\u001B[0m   total_size_str \u001B[38;5;241m=\u001B[39m tf_utils\u001B[38;5;241m.\u001B[39mbytes_to_readable_str(\n\u001B[0;32m    195\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_total_bytes_downloaded, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    196\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_print_download_progress_msg(\n\u001B[0;32m    197\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDownloaded \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m, Total size: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_url, total_size_str),\n\u001B[0;32m    198\u001B[0m       flush\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Engieering Thesis\\Adversarial_Attacks\\.venv\\lib\\site-packages\\tensorflow_hub\\file_utils.py:52\u001B[0m, in \u001B[0;36mextract_tarfile_to_destination\u001B[1;34m(fileobj, dst_path, log_function)\u001B[0m\n\u001B[0;32m     49\u001B[0m abs_target_path \u001B[38;5;241m=\u001B[39m merge_relative_path(dst_path, tarinfo\u001B[38;5;241m.\u001B[39mname)\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tarinfo\u001B[38;5;241m.\u001B[39misfile():\n\u001B[1;32m---> 52\u001B[0m   \u001B[43mextract_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtgz\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarinfo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mabs_target_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_function\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_function\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m tarinfo\u001B[38;5;241m.\u001B[39misdir():\n\u001B[0;32m     54\u001B[0m   tf\u001B[38;5;241m.\u001B[39mcompat\u001B[38;5;241m.\u001B[39mv1\u001B[38;5;241m.\u001B[39mgfile\u001B[38;5;241m.\u001B[39mMakeDirs(abs_target_path)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Engieering Thesis\\Adversarial_Attacks\\.venv\\lib\\site-packages\\tensorflow_hub\\file_utils.py:35\u001B[0m, in \u001B[0;36mextract_file\u001B[1;34m(tgz, tarinfo, dst_path, buffer_size, log_function)\u001B[0m\n\u001B[0;32m     33\u001B[0m dst \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mcompat\u001B[38;5;241m.\u001B[39mv1\u001B[38;5;241m.\u001B[39mgfile\u001B[38;5;241m.\u001B[39mGFile(dst_path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 35\u001B[0m   buf \u001B[38;5;241m=\u001B[39m \u001B[43msrc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbuffer_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     36\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m buf:\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tarfile.py:696\u001B[0m, in \u001B[0;36m_FileInFile.readinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m    695\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mreadinto\u001B[39m(\u001B[38;5;28mself\u001B[39m, b):\n\u001B[1;32m--> 696\u001B[0m     buf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    697\u001B[0m     b[:\u001B[38;5;28mlen\u001B[39m(buf)] \u001B[38;5;241m=\u001B[39m buf\n\u001B[0;32m    698\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(buf)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tarfile.py:685\u001B[0m, in \u001B[0;36m_FileInFile.read\u001B[1;34m(self, size)\u001B[0m\n\u001B[0;32m    683\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m data:\n\u001B[0;32m    684\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfileobj\u001B[38;5;241m.\u001B[39mseek(offset \u001B[38;5;241m+\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mposition \u001B[38;5;241m-\u001B[39m start))\n\u001B[1;32m--> 685\u001B[0m     b \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfileobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlength\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    686\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(b) \u001B[38;5;241m!=\u001B[39m length:\n\u001B[0;32m    687\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ReadError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munexpected end of data\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tarfile.py:522\u001B[0m, in \u001B[0;36m_Stream.read\u001B[1;34m(self, size)\u001B[0m\n\u001B[0;32m    520\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Return the next size number of bytes from the stream.\"\"\"\u001B[39;00m\n\u001B[0;32m    521\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 522\u001B[0m buf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    523\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpos \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(buf)\n\u001B[0;32m    524\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m buf\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tarfile.py:540\u001B[0m, in \u001B[0;36m_Stream._read\u001B[1;34m(self, size)\u001B[0m\n\u001B[0;32m    538\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuf \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    539\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 540\u001B[0m     buf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfileobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbufsize\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    541\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m buf:\n\u001B[0;32m    542\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:466\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[1;34m(self, amt)\u001B[0m\n\u001B[0;32m    463\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m amt \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength:\n\u001B[0;32m    464\u001B[0m     \u001B[38;5;66;03m# clip the read to the \"end of response\"\u001B[39;00m\n\u001B[0;32m    465\u001B[0m     amt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength\n\u001B[1;32m--> 466\u001B[0m s \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    467\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m s \u001B[38;5;129;01mand\u001B[39;00m amt:\n\u001B[0;32m    468\u001B[0m     \u001B[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001B[39;00m\n\u001B[0;32m    469\u001B[0m     \u001B[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001B[39;00m\n\u001B[0;32m    470\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_conn()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py:705\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    704\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 705\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[0;32m    707\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1274\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[1;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[0;32m   1270\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1271\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1272\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[0;32m   1273\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[1;32m-> 1274\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1275\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1276\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1130\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[1;34m(self, len, buffer)\u001B[0m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1129\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1130\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1131\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1132\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Wizualizacja wyników\n",
    "\n",
    "### Podświetlone różnice w tekście\n",
    "Możemy wyświetlić oryginalny i zaburzony tekst z podświetlonymi różnicami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    # Wyświetl reprezentację HTML wyniku, pokazującą różnice\n",
    "    display(HTML(result.__str__(color_method='html')))\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statystyki podsumowujące\n",
    "\n",
    "Spójrzmy na wskaźnik sukcesu i inne metryki."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T18:52:11.515333Z",
     "start_time": "2026-01-24T18:52:11.188993Z"
    }
   },
   "source": [
    "# Oblicz statystyki\n",
    "num_success = 0\n",
    "num_failed = 0\n",
    "num_skipped = 0\n",
    "\n",
    "for result in results:\n",
    "    # Sprawdź typ wyniku ataku\n",
    "    if isinstance(result, textattack.attack_results.SuccessfulAttackResult):\n",
    "        num_success += 1\n",
    "    elif isinstance(result, textattack.attack_results.FailedAttackResult):\n",
    "        num_failed += 1\n",
    "    elif isinstance(result, textattack.attack_results.SkippedAttackResult):\n",
    "        num_skipped += 1\n",
    "\n",
    "print(f\"Sukcesy: {num_success}\")\n",
    "print(f\"Porażki: {num_failed}\")\n",
    "print(f\"Pominięte: {num_skipped}\")\n",
    "\n",
    "# Rysowanie wykresu słupkowego\n",
    "labels = ['Sukces', 'Porażka', 'Pominięte']\n",
    "values = [num_success, num_failed, num_skipped]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(labels, values, color=['green', 'red', 'gray'])\n",
    "plt.title('Podsumowanie wyników ataku')\n",
    "plt.xlabel('Typ wyniku')\n",
    "plt.ylabel('Liczba')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m num_failed \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      4\u001B[0m num_skipped \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m result \u001B[38;5;129;01min\u001B[39;00m \u001B[43mresults\u001B[49m:\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;66;03m# Sprawdź typ wyniku ataku\u001B[39;00m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, textattack\u001B[38;5;241m.\u001B[39mattack_results\u001B[38;5;241m.\u001B[39mSuccessfulAttackResult):\n\u001B[0;32m      9\u001B[0m         num_success \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'results' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretacja wyników\n",
    "\n",
    "Wykres słupkowy przedstawia podsumowanie skuteczności ataku adwersarzowego na wybranej próbce danych. Poniżej znajduje się wyjaśnienie poszczególnych kategorii:\n",
    "\n",
    "- **Sukces (Success)**: Liczba przykładów, dla których atak zakończył się powodzeniem. Oznacza to, że algorytm zdołał zmodyfikować tekst wejściowy w taki sposób, że model zmienił swoją predykcję (np. z \"spam\" na \"nie-spam\"), zachowując jednocześnie semantyczne podobieństwo do oryginału.\n",
    "\n",
    "- **Porażka (Failed)**: Liczba przykładów, dla których atak nie powiódł się. Algorytm nie był w stanie znaleźć takiej modyfikacji tekstu, która zmyliłaby model, przy zachowaniu zadanych ograniczeń (np. maksymalna liczba zmienionych słów, minimalne podobieństwo semantyczne).\n",
    "\n",
    "- **Pominięte (Skipped)**: Liczba przykładów, które zostały pominięte w procesie ataku. Najczęściej dzieje się tak, gdy model błędnie sklasyfikował oryginalny tekst jeszcze przed atakiem. Ataki adwersarzowe zazwyczaj przeprowadza się tylko na poprawnie sklasyfikowanych przykładach, aby mierzyć skuteczność samego ataku, a nie błędy modelu."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from textattack.attack_results import SuccessfulAttackResult, FailedAttackResult, SkippedAttackResult\n",
    "\n",
    "# 1. Obliczanie statystyk na podstawie rzeczywistych wyników ataku\n",
    "total_attacks = len(results)\n",
    "num_success = sum(1 for r in results if isinstance(r, SuccessfulAttackResult))\n",
    "num_failed = sum(1 for r in results if isinstance(r, FailedAttackResult))\n",
    "num_skipped = sum(1 for r in results if isinstance(r, SkippedAttackResult))\n",
    "\n",
    "# Obliczanie dokładności (Accuracy) i skuteczności (Success Rate)\n",
    "# Original Accuracy = (Succeeded + Failed) / Total\n",
    "original_accuracy = ((num_success + num_failed) / total_attacks) * 100 if total_attacks > 0 else 0\n",
    "# Accuracy under Attack = Failed / Total\n",
    "accuracy_under_attack = (num_failed / total_attacks) * 100 if total_attacks > 0 else 0\n",
    "# Attack Success Rate = Succeeded / (Succeeded + Failed)\n",
    "attack_success_rate = (num_success / (num_success + num_failed)) * 100 if (num_success + num_failed) > 0 else 0\n",
    "\n",
    "# Obliczanie średniego stopnia perturbacji (zmiany słów)\n",
    "perturbation_percentages = []\n",
    "for r in results:\n",
    "    if isinstance(r, SuccessfulAttackResult):\n",
    "        orig_words = len(r.original_result.attacked_text.words)\n",
    "        pert_words = r.num_words_changed\n",
    "        perturbation_percentages.append((pert_words / orig_words) * 100 if orig_words > 0 else 0)\n",
    "\n",
    "avg_pert = sum(perturbation_percentages) / len(perturbation_percentages) if perturbation_percentages else 0\n",
    "\n",
    "# 2. Tworzenie syntetycznej tabeli wyników\n",
    "summary_data = {\n",
    "    \"Metryka\": [\n",
    "        \"Liczba analizowanych próbek\",\n",
    "        \"Udane ataki (Succeeded)\",\n",
    "        \"Nieudane ataki (Failed)\",\n",
    "        \"Pominięte (Skipped - model już się mylił)\",\n",
    "        \"Dokładność przed atakiem\",\n",
    "        \"Dokładność po ataku\",\n",
    "        \"Skuteczność ataku (Success Rate)\",\n",
    "        \"Średni % zmienionych słów\"\n",
    "    ],\n",
    "    \"Wartość\": [\n",
    "        total_attacks,\n",
    "        num_success,\n",
    "        num_failed,\n",
    "        num_skipped,\n",
    "        f\"{original_accuracy:.1f}%\",\n",
    "        f\"{accuracy_under_attack:.1f}%\",\n",
    "        f\"{attack_success_rate:.1f}%\",\n",
    "        f\"{avg_pert:.1f}%\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "print(\"### ZESTAWIENIE WYNIKÓW ATAKU ADWERSARIALNEGO ###\")\n",
    "display(df_summary)\n",
    "\n",
    "# 3. Wizualizacja wpływu ataku na skuteczność filtra\n",
    "plt.figure(figsize=(10, 6))\n",
    "labels = ['Dokładność Oryginalna', 'Dokładność pod Atakiem']\n",
    "values = [original_accuracy, accuracy_under_attack]\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "\n",
    "bars = plt.bar(labels, values, color=colors, width=0.6)\n",
    "plt.ylabel('Dokładność (%)')\n",
    "plt.title(f'Wpływ ataku {attack_recipe} na filtr spamu (BERT-Tiny)')\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "# Dodanie etykiet procentowych nad słupkami\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 2, f'{yval:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 4. Analiza i wnioski\n",
    "print(\"\\n### ANALIZA I WNIOSKI ###\")\n",
    "analysis = f\"\"\"\n",
    "1. ILE (Skala zjawiska):\n",
    "   - Atakujący zdołał oszukać model w {num_success} na {num_success + num_failed} przypadkach, w których model początkowo działał poprawnie.\n",
    "   - Skuteczność ataku (Success Rate) wyniosła {attack_success_rate:.1f}%, co drastycznie obniżyło realną wartość filtra spamu.\n",
    "\n",
    "2. JAK (Metoda manipulacji):\n",
    "   - Metoda {attack_recipe} (TextBugger) wykorzystała hybrydowe podejście:\n",
    "     - Na poziomie słów: zamiana na synonimy (np. 'urgent' -> 'immediate').\n",
    "     - Na poziomie znaków: wprowadzanie \"bugów\" (literówki, zamiany znaków na wizualnie podobne, np. 'o' -> '0').\n",
    "   - Średnio wystarczyło zmienić zaledwie {avg_pert:.1f}% tekstu, aby wiadomość sklasyfikowana jako SPAM została uznana za bezpieczną (HAM).\n",
    "\n",
    "3. JAKI WPŁYW (Konsekwencje):\n",
    "   - Model BERT-Tiny, mimo wysokiej wydajności, wykazuje dużą wrażliwość na drobne perturbacje znakowe.\n",
    "   - Dla użytkownika końcowego wiadomość pozostaje w pełni czytelna (np. \"C0ngratulations!\"), ale dla algorytmu\n",
    "     wektor wejściowy zmienia się na tyle, że predykcja zostaje całkowicie odwrócona.\n",
    "   - Wniosek: Filtry spamu oparte na prostych transformerach wymagają dodatkowego wzmocnienia (np. Adversarial Training)\n",
    "     lub filtrów normalizujących tekst przed klasyfikacją.\n",
    "\"\"\"\n",
    "print(analysis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
